{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from IPython.display import display\n",
    "from time import strftime, gmtime\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "import yaml\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from Redshift "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = yaml.load(open('./vars.yaml', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_username = conf['REDSHIFT_USER']\n",
    "rs_password = conf['REDSHIFT_PASSWORD']\n",
    "rs_db = conf['REDSHIFT_DB']\n",
    "rs_host = conf['REDSHIFT_HOST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f'redshift+psycopg2://{rs_username}:{rs_password}@{rs_host}:5439/{rs_db}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_get_dataset = '''\n",
    "SELECT\n",
    "isfraud\n",
    ", amount\n",
    ", diff_dest_equal_amount\n",
    ", diff_origin_equal_amount\n",
    ", is_cash_in\n",
    ", is_cash_out\n",
    ", is_debit\n",
    ", is_payment\n",
    ", is_transfer\n",
    ", namedest_c\n",
    ", nameorig_c\n",
    ", newbalancedest\n",
    ", newbalanceorig\n",
    ", oldbalancedest\n",
    ", oldbalanceorg\n",
    ", step\n",
    "FROM dataset\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(sql_get_dataset, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isfraud</th>\n",
       "      <th>amount</th>\n",
       "      <th>diff_dest_equal_amount</th>\n",
       "      <th>diff_origin_equal_amount</th>\n",
       "      <th>is_cash_in</th>\n",
       "      <th>is_cash_out</th>\n",
       "      <th>is_debit</th>\n",
       "      <th>is_payment</th>\n",
       "      <th>is_transfer</th>\n",
       "      <th>namedest_c</th>\n",
       "      <th>nameorig_c</th>\n",
       "      <th>newbalancedest</th>\n",
       "      <th>newbalanceorig</th>\n",
       "      <th>oldbalancedest</th>\n",
       "      <th>oldbalanceorg</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.993023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.204926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.230799</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4.067039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.475480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.618623</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.604805</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.426836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.408535</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.399719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.705094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.194464</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.654177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   isfraud    amount  diff_dest_equal_amount  diff_origin_equal_amount  \\\n",
       "0        0  3.993023                       0                         0   \n",
       "1        0  4.067039                       0                         0   \n",
       "2        0  3.604805                       0                         0   \n",
       "3        0  3.408535                       0                         1   \n",
       "4        0  3.194464                       0                         0   \n",
       "\n",
       "   is_cash_in  is_cash_out  is_debit  is_payment  is_transfer  namedest_c  \\\n",
       "0           0            0         0           1            0           0   \n",
       "1           0            0         0           1            0           0   \n",
       "2           0            0         0           1            0           0   \n",
       "3           0            0         0           1            0           0   \n",
       "4           0            0         0           1            0           0   \n",
       "\n",
       "   nameorig_c  newbalancedest  newbalanceorig  oldbalancedest  oldbalanceorg  \\\n",
       "0           1             0.0        5.204926             0.0       5.230799   \n",
       "1           1             0.0        4.475480             0.0       4.618623   \n",
       "2           1             0.0        0.000000             0.0       3.426836   \n",
       "3           1             0.0        3.399719             0.0       3.705094   \n",
       "4           1             0.0        0.000000             0.0       2.654177   \n",
       "\n",
       "   step  \n",
       "0     1  \n",
       "1     1  \n",
       "2     1  \n",
       "3     1  \n",
       "4     1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span style=\"font-weight: 400;\">Usually in ML you can split the data into two parts: <em>Train</em> and <em>Test</em>. When applying HyperParameter Optimization, it's important to also have a <em>Validation</em> set.</span></p>\n",
    "<p><span style=\"text-decoration: underline;\"><span style=\"font-weight: 400;\">In this case we will split the data to 4! Why?</span></span></p>\n",
    "<ol>\n",
    "<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">The </span><span style=\"color: #3366ff;\"><strong>Train</strong></span><span style=\"font-weight: 400;\"> set will be used to fit the model using hyper parameter optimization.</span></li>\n",
    "<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">The </span><span style=\"color: #993366;\"><strong>Validation</strong></span><span style=\"font-weight: 400;\"> set is going to be used for validation while training.</span></li>\n",
    "<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">The </span><span style=\"color: #ff9900;\"><strong>Test</strong></span><span style=\"font-weight: 400;\"> set is going to evaluate the best performing model on the validation set.</span></li>\n",
    "<li style=\"font-weight: 400;\">The <span style=\"color: #008080;\"><strong>fourth</strong></span> and final part will be used in the Capstone project to simulate new data - since our dataset is finite and we would like to demonstrate how to improve the model on future data.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_end_step: 281.0\n",
      "test_end_step: 355.0\n",
      "validation_end_step: 399.0\n"
     ]
    }
   ],
   "source": [
    "quantiles = df['step'].quantile([0.6,0.8,0.9]).tolist()\n",
    "train_end_step, test_end_step, validation_end_step = quantiles\n",
    "print('train_end_step:' , train_end_step)\n",
    "print('test_end_step:' , test_end_step)\n",
    "print('validation_end_step:' , validation_end_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['step'] < train_end_step]\n",
    "df_test = df[(df['step'] >= train_end_step) & (df['step'] < test_end_step)]\n",
    "df_validation = df[(df['step'] >= test_end_step) & (df['step'] < validation_end_step)]\n",
    "df_new_data = df[(df['step'] >= validation_end_step)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'aws-capstone-gad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 mb s3://{bucket}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train_path = f's3://{bucket}/data/train/train.csv'\n",
    "s3_test_path = f's3://{bucket}/data/test/test.csv'\n",
    "s3_val_path = f's3://{bucket}/data/val/val.csv'\n",
    "s3_new_data_path = f's3://{bucket}/data/new_data/new_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data to S3 for training\n",
    "df_train.drop('step', axis=1).to_csv(s3_train_path, index=None, header=None)\n",
    "df_test.drop('step', axis=1).to_csv(s3_test_path, index=None, header=None)\n",
    "df_validation.drop('step', axis=1).to_csv(s3_val_path, index=None, header=None)\n",
    "df_new_data.drop('step', axis=1).to_csv(s3_new_data_path, index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the hyper parameter training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = sagemaker.image_uris.retrieve('xgboost', boto3.Session().region_name, 'latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    instance_count=1, \n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, 'models'),\n",
    "                                    sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.set_hyperparameters(eval_metric='auc',\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=4000,\n",
    "                        rate_drop=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {'eta': ContinuousParameter(0, 1),\n",
    "                        'min_child_weight': ContinuousParameter(20, 1000),\n",
    "                        'alpha': ContinuousParameter(0, 2),\n",
    "                        'max_depth': IntegerParameter(4, 15)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = 'validation:auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(xgb,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=10,\n",
    "                            max_parallel_jobs=5, \n",
    "                            early_stopping_type='Auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = TrainingInput(s3_data=s3_train_path.replace('train.csv', ''), content_type='csv')\n",
    "s3_input_validation = TrainingInput(s3_data=s3_val_path.replace('val.csv', ''), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................................................................................................................................."
     ]
    }
   ],
   "source": [
    "tuner.fit({'train': s3_input_train, 'validation': s3_input_validation}, include_cls_metadata=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
